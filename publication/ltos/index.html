<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.0" />
    <meta name="author" content="Zongqing Lu">
    <meta name="description" content="Associate Professor">

    <link rel="stylesheet" href="https://z0ngqing.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://z0ngqing.github.io/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://z0ngqing.github.io/publication/ltos/">

    <title>[NIPS&#39;22] Learning to Share in Multi-Agent Reinforcement Learning | Zongqing&#39;s Homepage</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://z0ngqing.github.io/">Zongqing&#39;s Homepage</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#news">News</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#projects">Lab</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#teaching">Teaching</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#services">Services</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#contact">Contact</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <div class="pub" itemscope itemtype="http://schema.org/CreativeWork">
        <div class="pub-title">
            <h1 itemprop="name">[NIPS&#39;22] Learning to Share in Multi-Agent Reinforcement Learning</h1>
            <span class="pub-authors" itemprop="author">
                
                Yuxuan Yi, Ge Li, Yaowei Wang, and Zongqing Lu
                
            </span>
            <span class="pull-right">
                
<div class="share-box">
    <ul class="share">
        <li>
            <a class="facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fltos%2f" target="_blank">
                <i class="fa fa-facebook"></i>
            </a>
        </li>
        <li>
            <a class="twitter" href="https://twitter.com/intent/tweet?text=%5bNIPS%2722%5d%20Learning%20to%20Share%20in%20Multi-Agent%20Reinforcement%20Learning&amp;url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fltos%2f" target="_blank">
                <i class="fa fa-twitter"></i>
            </a>
        </li>
        <li>
            <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fltos%2f&amp;title=%5bNIPS%2722%5d%20Learning%20to%20Share%20in%20Multi-Agent%20Reinforcement%20Learning" target="_blank">
                <i class="fa fa-linkedin"></i>
            </a>
        </li>
        <li>
            <a class="weibo" href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fltos%2f&amp;title=%5bNIPS%2722%5d%20Learning%20to%20Share%20in%20Multi-Agent%20Reinforcement%20Learning" target="_blank">
                <i class="fa fa-weibo"></i>
            </a>
        </li>
        <li>
            <a class="email" href="mailto:?subject=%5bNIPS%2722%5d%20Learning%20to%20Share%20in%20Multi-Agent%20Reinforcement%20Learning&amp;body=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fltos%2f">
                <i class="fa fa-envelope"></i>
            </a>
        </li>
    </ul>
</div>


            </span>
        </div>

        

        <h3>Abstract</h3>

	<p align="justify" class="pub-abstract" itemprop="text">In this paper, we study the problem of networked multi-agent reinforcement learning (MARL), where a number of agents are deployed as a partially connected network and each interacts only with nearby agents. Networked MARL requires all agents to make decisions in a decentralized manner to optimize a global objective with restricted communication between neighbors over the network. Inspired by the fact that sharing plays a key role in human&rsquo;s learning of cooperation, we propose LToS, a hierarchically decentralized MARL framework that enables agents to learn to dynamically share reward with neighbors so as to encourage agents to cooperate on the global objective through collectives. For each agent, the high-level policy learns how to share reward with neighbors to decompose the global objective, while the low-level policy learns to optimize the local objective induced by the high-level policies in the neighborhood. The two policies form a bi-level optimization and learn alternately. We empirically demonstrate that LToS outperforms existing methods in both social dilemma and networked MARL scenarios across scales.</p>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
                    <div class="col-xs-12 col-sm-9"><em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
                    <div class="col-xs-12 col-sm-9" itemprop="datePublished">October, 2022</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row" style="padding-top: 10px">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
                    <div class="col-xs-12 col-sm-9">

                        




<a class="btn btn-primary btn-outline" href="https://openreview.net/pdf?id=0vJH6C_h4-">PDF</a>


<a class="btn btn-primary btn-outline" href="https://github.com/PKU-RL/RoadnetSZ">Code</a>
<a class="btn btn-primary btn-outline" href="https://github.com/PKU-RL/RoadnetSZ">Dataset</a>
<a class="btn btn-primary btn-outline" href="https://z0ngqing.github.io/project/cooperation/">Project</a>


<a class="btn btn-primary btn-outline" href="https://mobile.twitter.com/GamificationMAS/status/1526217447665283074?cxt=HHwWhMC9odarm64qAAAA">Best Cooperative AI Paper Award</a>

<a class="btn btn-primary btn-outline" href="https://www.gamificationmas.com/home">ICLRâ€™22 Workshop on GamificationMAS</a>

<a class="btn btn-primary btn-outline" href="https://sites.google.com/view/collective-learning/home?authuser=0">ICLR&#39;22 Workshop on Cells2Societies (oral)</a>



                    </div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="space-below"></div>

        <div class="article-style"></div>

    </div>

    <nav>
    <ul class="pager">
    	
        
        

        
        
        
    </ul>
</nav>


</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">

            &copy; 2025 Zongqing Lu &middot; 

            Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://z0ngqing.github.io/js/jquery-1.12.3.min.js"></script>
        <script src="https://z0ngqing.github.io/js/bootstrap.min.js"></script>
        <script src="https://z0ngqing.github.io/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'G-ZKGTRY33CM', 'auto');
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

