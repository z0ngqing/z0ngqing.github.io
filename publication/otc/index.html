<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.0" />
    <meta name="author" content="Zongqing Lu">
    <meta name="description" content="Associate Professor">

    <link rel="stylesheet" href="https://z0ngqing.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://z0ngqing.github.io/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://z0ngqing.github.io/publication/otc/">

    <title>[AAAI&#39;23] Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning | Zongqing&#39;s Homepage</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://z0ngqing.github.io/">Zongqing&#39;s Homepage</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#news">News</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#projects">Lab</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#teaching">Teaching</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#services">Services</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#contact">Contact</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <div class="pub" itemscope itemtype="http://schema.org/CreativeWork">
        <div class="pub-title">
            <h1 itemprop="name">[AAAI&#39;23] Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning</h1>
            <span class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </span>
            <span class="pull-right">
                
<div class="share-box">
    <ul class="share">
        <li>
            <a class="facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fotc%2f" target="_blank">
                <i class="fa fa-facebook"></i>
            </a>
        </li>
        <li>
            <a class="twitter" href="https://twitter.com/intent/tweet?text=%5bAAAI%2723%5d%20Online%20Tuning%20for%20Offline%20Decentralized%20Multi-Agent%20Reinforcement%20Learning&amp;url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fotc%2f" target="_blank">
                <i class="fa fa-twitter"></i>
            </a>
        </li>
        <li>
            <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fotc%2f&amp;title=%5bAAAI%2723%5d%20Online%20Tuning%20for%20Offline%20Decentralized%20Multi-Agent%20Reinforcement%20Learning" target="_blank">
                <i class="fa fa-linkedin"></i>
            </a>
        </li>
        <li>
            <a class="weibo" href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fotc%2f&amp;title=%5bAAAI%2723%5d%20Online%20Tuning%20for%20Offline%20Decentralized%20Multi-Agent%20Reinforcement%20Learning" target="_blank">
                <i class="fa fa-weibo"></i>
            </a>
        </li>
        <li>
            <a class="email" href="mailto:?subject=%5bAAAI%2723%5d%20Online%20Tuning%20for%20Offline%20Decentralized%20Multi-Agent%20Reinforcement%20Learning&amp;body=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fotc%2f">
                <i class="fa fa-envelope"></i>
            </a>
        </li>
    </ul>
</div>


            </span>
        </div>

        

        <h3>Abstract</h3>

	<p align="justify" class="pub-abstract" itemprop="text">Offline reinforcement learning could learn effective policies from a fixed dataset, which is promising for real-world applications. However, in offline decentralized multi-agent reinforcement learning, due to the discrepancy between the behavior policy and learned policy, the transition dynamics in offline experiences do not accord with the transition dynamics in online execution, which creates severe errors in value estimates, leading to uncoordinated low-performing policies. One way to overcome this problem is to bridge offline training and online tuning. However, considering both deployment efficiency and sample efficiency, we could only collect very limited online experiences, making it insufficient to use merely online data for updating the agent policy. To utilize both offline and online experiences to tune the policies of agents, we introduce online transition correction (OTC) to implicitly correct the offline transition dynamics by modifying sampling probabilities. We design two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and further propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. OTC is simple yet effective to increase data efficiency and improve agent policies in online tuning. Empirically, OTC outperforms baselines in a variety of tasks.</p>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
                    <div class="col-xs-12 col-sm-9"><em>Thirty-Seventh AAAI Conference on Artificial Intelligence</em> (AAAI), February 7-14, 2023.</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
                    <div class="col-xs-12 col-sm-9" itemprop="datePublished">January, 2023</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row" style="padding-top: 10px">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
                    <div class="col-xs-12 col-sm-9">

                        




<a class="btn btn-primary btn-outline" href="https://ojs.aaai.org/index.php/AAAI/article/view/25973">PDF</a>




<a class="btn btn-primary btn-outline" href="https://z0ngqing.github.io/project/learning/">Project</a>




                    </div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="space-below"></div>

        <div class="article-style"></div>

    </div>

    <nav>
    <ul class="pager">
    	
        
        

        
        
        
    </ul>
</nav>


</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">

            &copy; 2026 Zongqing Lu &middot; 

            Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://z0ngqing.github.io/js/jquery-1.12.3.min.js"></script>
        <script src="https://z0ngqing.github.io/js/bootstrap.min.js"></script>
        <script src="https://z0ngqing.github.io/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'G-ZKGTRY33CM', 'auto');
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

