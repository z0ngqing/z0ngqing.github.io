<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.0" />
    <meta name="author" content="Zongqing Lu">
    <meta name="description" content="Associate Professor">

    <link rel="stylesheet" href="https://z0ngqing.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://z0ngqing.github.io/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://z0ngqing.github.io/publication/mcq/">

    <title>[NIPS&#39;22] Mildly Conservative Q-Learning for Offline Reinforcement Learning | Zongqing&#39;s Homepage</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://z0ngqing.github.io/">Zongqing&#39;s Homepage</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#news">News</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#projects">Lab</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#teaching">Teaching</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#services">Services</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#contact">Contact</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <div class="pub" itemscope itemtype="http://schema.org/CreativeWork">
        <div class="pub-title">
            <h1 itemprop="name">[NIPS&#39;22] Mildly Conservative Q-Learning for Offline Reinforcement Learning</h1>
            <span class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Xiaoteng Ma, Xiu Li, and Zongqing Lu
                
            </span>
            <span class="pull-right">
                
<div class="share-box">
    <ul class="share">
        <li>
            <a class="facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fmcq%2f" target="_blank">
                <i class="fa fa-facebook"></i>
            </a>
        </li>
        <li>
            <a class="twitter" href="https://twitter.com/intent/tweet?text=%5bNIPS%2722%5d%20Mildly%20Conservative%20Q-Learning%20for%20Offline%20Reinforcement%20Learning&amp;url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fmcq%2f" target="_blank">
                <i class="fa fa-twitter"></i>
            </a>
        </li>
        <li>
            <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fmcq%2f&amp;title=%5bNIPS%2722%5d%20Mildly%20Conservative%20Q-Learning%20for%20Offline%20Reinforcement%20Learning" target="_blank">
                <i class="fa fa-linkedin"></i>
            </a>
        </li>
        <li>
            <a class="weibo" href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fmcq%2f&amp;title=%5bNIPS%2722%5d%20Mildly%20Conservative%20Q-Learning%20for%20Offline%20Reinforcement%20Learning" target="_blank">
                <i class="fa fa-weibo"></i>
            </a>
        </li>
        <li>
            <a class="email" href="mailto:?subject=%5bNIPS%2722%5d%20Mildly%20Conservative%20Q-Learning%20for%20Offline%20Reinforcement%20Learning&amp;body=https%3a%2f%2fz0ngqing.github.io%2fpublication%2fmcq%2f">
                <i class="fa fa-envelope"></i>
            </a>
        </li>
    </ul>
</div>


            </span>
        </div>

        

        <h3>Abstract</h3>

	<p align="justify" class="pub-abstract" itemprop="text">Offline reinforcement learning (RL) defines the task of learning from a static logged dataset without continually interacting with the environment. The distribution shift between the learned policy and the behavior policy makes it necessary for the value function to stay conservative such that out-of-distribution (OOD) actions will not be severely overestimated. However, existing approaches, penalizing the unseen actions or regularizing with the behavior policy, are too pessimistic, which suppresses the generalization of the value function and hinders the performance improvement. This paper explores mild but enough conservatism for offline learning while not harming generalization. We propose Mildly Conservative Q-learning (MCQ), where OOD actions are actively trained by assigning them proper pseudo Q values. We theoretically show that MCQ induces a policy that behaves at least as well as the behavior policy and no erroneous overestimation will occur for OOD actions. Experimental results on the D4RL benchmarks demonstrate that MCQ achieves remarkable performance compared with prior work. Furthermore, MCQ shows superior generalization ability when transferring from offline to online, and significantly outperforms baselines. Our code is publicly available at <a href="https://github.com/dmksjfl/MCQ">https://github.com/dmksjfl/MCQ</a>.</p>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
                    <div class="col-xs-12 col-sm-9"><em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
                    <div class="col-xs-12 col-sm-9" itemprop="datePublished">October, 2022</div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="row" style="padding-top: 10px">
            <div class="col-sm-1"></div>
            <div class="col-sm-10">
                <div class="row">
                    <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
                    <div class="col-xs-12 col-sm-9">

                        




<a class="btn btn-primary btn-outline" href="https://openreview.net/pdf?id=VYYf6S67pQc">PDF</a>


<a class="btn btn-primary btn-outline" href="https://github.com/dmksjfl/MCQ">Code</a>

<a class="btn btn-primary btn-outline" href="https://z0ngqing.github.io/project/learning/">Project</a>




                    </div>
                </div>
            </div>
            <div class="col-sm-1"></div>
        </div>
        <div class="visible-xs space-below"></div>

        <div class="space-below"></div>

        <div class="article-style"></div>

    </div>

    <nav>
    <ul class="pager">
    	
        
        

        
        
        
    </ul>
</nav>


</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">

            &copy; 2025 Zongqing Lu &middot; 

            Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://z0ngqing.github.io/js/jquery-1.12.3.min.js"></script>
        <script src="https://z0ngqing.github.io/js/bootstrap.min.js"></script>
        <script src="https://z0ngqing.github.io/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'G-ZKGTRY33CM', 'auto');
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

