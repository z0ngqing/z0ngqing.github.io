<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.0" />
    <meta name="author" content="Zongqing Lu">
    <meta name="description" content="BOYA Assistant Professor">

    <link rel="stylesheet" href="https://z0ngqing.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://z0ngqing.github.io/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://z0ngqing.github.io/project/rlapp/">

    <title>RL/MARL Applications | Zongqing&#39;s Homepage</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://z0ngqing.github.io/">Zongqing&#39;s Homepage</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#news">News</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#projects">Lab</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#teaching">Teaching</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#services">Services</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#contact">Contact</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <article class="article article-project" itemscope itemtype="http://schema.org/Article">
        
        <img src="https://z0ngqing.github.io/img/banners/traffic.png" class="article-banner" itemprop="image">
        

        <h1 itemprop="name">RL/MARL Applications</h1>
        
        

<div class="article-metadata">

    
    
    
    <span class="article-tags">
        <i class="fa fa-tags"></i>
        
        <a class="article-tag-link" href="https://z0ngqing.github.io/tags/reinforcement-learning">Reinforcement Learning</a>, 
        
        <a class="article-tag-link" href="https://z0ngqing.github.io/tags/applications">Applications</a>
        
    </span>
    
    

    

</div>


        

        <div align="justify" class="article-style" itemprop="articleBody">
            

<p>Reinforcement learning (RL) has the potential be applied to many real-world applications. In our research, we also investigate the applications of RL and Multi-agent RL. Currently, we have been investigating two applications: one is traffic signal control; another is EDA. Traffic signals coordinating traffic movements are the key for transportation efficiency. However, conventional traffic signal control that heavily relies on pre-defined rules and assumptions on traffic conditions is far from intelligence. RL that learns from directly interacting with the environment has great potential to be applied to traffic signal control for building smart cities. EDA has many combinatorial optimization problems. Many of them are currently solved by heuristics, which usually obtain the performance far from the optimal. How to achieve better performance has been a long-standing prbolem. RL that aims to optimize the long-term return naturally fits many problems in EDA. Therefore, we also pay attention to solving the problems of EDA. In the following, we introduce some of our studies. For detail, please refer to the paper.</p>

<h3 id="hilight">HiLight</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/hilight.png" width="300" class="article-style" itemprop="image">
The objective of traffic signal control is to optimize average travel time, which is a delayed reward in a long time horizon in the context of RL. However, existing work simplifies the optimization by using queue length, waiting time, delay, etc., as immediate reward and presumes these short-term targets are always aligned with the objective. Nevertheless, these targets may deviate from the objective in different road networks with various traffic patterns. Moreover, it remains unsolved how to cooperatively control traffic signals to directly optimize average travel time. To address these challenges, we propose a hierarchical and cooperative reinforcement learning method-HiLight. HiLight enables each agent to learn a high-level policy that optimizes the objective locally by selecting among the sub-policies that respectively optimize short-term targets. Moreover, the high-level policy additionally considers the objective in the neighborhood with adaptive weighting to encourage agents to cooperate on the objective in the road network. Empirically, we demonstrate that HiLight outperforms state-of-the-art RL methods for traffic signal control in real road networks with real traffic.</p>

<h3 id="net-oder-exploration-in-detailed-routing">Net Oder Exploration in Detailed Routing</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/netorder.png" width="450" class="article-style" itemprop="image">
The net orders in detailed routing are crucial to routing closure, especially in most modern routers following the sequential routing manner with the rip-up and reroute scheme. In advanced technology nodes, detailed routing has to deal with complicated design rules and large problem sizes, making its performance more sensitive to the order of nets to be routed. In literature, the net orders are mostly determined by simple heuristic rules tuned for specific benchmarks. We propose an asynchronous reinforcement learning (RL) framework to search for optimal ordering strategies automatically. By asynchronous querying the router and training the RL agents, we can generate high-performance routing sequences to achieve better solution quality.</p>

        </div>


        <div align="justify" class="article-style" itemprop="articleBody">
            
                
            
                
            
                
            
                
            
                
            
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
        </div>

        <div>
        
            <br>
            <h3>Publications</h3>
            
                
                    
                
            
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                        <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/date21/" itemprop="url">[DATE&#39;21] Asynchronous Reinforcement Learning Framework for Net Order Exploration in Detailed Routing</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Tong Qu, Yibo Lin, Zongqing Lu, Yajun Su, and Yayi Wei
                
            </div>

            <div class="pub-publication">
                
                    <em>Design, Automation and Test in Europe Conference</em> (DATE), February 1-5, 2021.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                    
                
            
                
                    
                        <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/aaai21/" itemprop="url">[AAAI&#39;21] Hierarchically and Cooperatively Learning Traffic Signal Control</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Bingyu Xu, Yaowei Wang, Zhaozhi Wang, Huizhu Jia, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Fifth AAAI Conference on Artificial Intelligence</em> (AAAI), February 2-9, 2021.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 21%=<sup>1692</sup>&frasl;<sub>7911</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                    
                
            
                
                    
                        <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mtlight/" itemprop="url">MTLight: Efficient Multi-Task Reinforcement Learning for Traffic Signal Control</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Liwen Zhu, Peixi Peng, Zongqing Lu, and Yonghong Tian
                
            </div>

            <div class="pub-publication">
                
                    ICLR 2022 Workshop on Gamification and Multiagent Solutions.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                        <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/tcad21/" itemprop="url">[TCAD] Asynchronous Reinforcement Learning Framework and Knowledge Transfer for Net Order Exploration in Detailed Routing</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Yibo Lin, Tong Qu, Zongqing Lu, Yajun Su, and Yayi Wei
                
            </div>

            <div class="pub-publication">
                
                    <em>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</em>, vol 41, no. 9, pp 3132 - 3142, 2022
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                        <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/tkde23/" itemprop="url">[TKDE] MetaVIM: Meta Variationally Intrinsic Motivated Reinforcement Learning for Decentralized Traffic Signal Control</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Liwen Zhu, Peixi Peng, Zongqing Lu, Yonghong Tian
                
            </div>

            <div class="pub-publication">
                
                    <em>IEEE Transactions on Knowledge and Data Engineering</em> (online)
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
                
                    
                        <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/ma2ml/" itemprop="url">[CVPR&#39;23] Multi-Agent Automated Machine Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Zhaozhi Wang, Kefan Su, Jian Zhang, Huizhu Jia, Qixiang Ye, Xiaodong Xie, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>IEEE / CVF Computer Vision and Pattern Recognition Conference</em> (CVPR), Jun 18-22, 2023.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25.78%=<sup>2360</sup>&frasl;<sub>9155</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                    
                
            
        
        </div>
    </article>
    
    <nav>
    <ul class="pager">
    	
        
        <li class="previous"><a href="https://z0ngqing.github.io/project/video/"><span aria-hidden="true">&larr;</span> Distributed Video Processing Using Deep Learning on Networked Devices</a></li>
        
        

        
        
        <li class="next"><a href="https://z0ngqing.github.io/project/learning/">RL/Multi-Agent RL <span aria-hidden="true">&rarr;</span></a></li>
        
        
    </ul>
</nav>


</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">

            &copy; 2022 Zongqing Lu &middot; 

            Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://z0ngqing.github.io/js/jquery-1.12.3.min.js"></script>
        <script src="https://z0ngqing.github.io/js/bootstrap.min.js"></script>
        <script src="https://z0ngqing.github.io/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-88925956-1', 'auto');
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

