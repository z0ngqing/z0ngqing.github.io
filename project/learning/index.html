<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.55.0" />
    <meta name="author" content="Zongqing Lu">
    <meta name="description" content="Associate Professor">

    <link rel="stylesheet" href="https://z0ngqing.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
    <link rel="stylesheet" href="https://z0ngqing.github.io/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://z0ngqing.github.io/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://z0ngqing.github.io/project/learning/">

    <title>RL/Multi-Agent RL | Zongqing&#39;s Homepage</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://z0ngqing.github.io/">Zongqing&#39;s Homepage</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#news">News</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#projects">Lab</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#teaching">Teaching</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#services">Services</a></li>
                
                <li class="nav-item"><a href="https://z0ngqing.github.io/#contact">Contact</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <article class="article article-project" itemscope itemtype="http://schema.org/Article">
        
        <img src="https://z0ngqing.github.io/img/banners/learning.png" class="article-banner" itemprop="image">
        

        <h1 itemprop="name">RL/Multi-Agent RL</h1>
        
        

<div class="article-metadata">

    
    
    
    <span class="article-tags">
        <i class="fa fa-tags"></i>
        
        <a class="article-tag-link" href="https://z0ngqing.github.io/tags/reinforcement-learning">Reinforcement Learning</a>, 
        
        <a class="article-tag-link" href="https://z0ngqing.github.io/tags/multiagent-learning">Multiagent Learning</a>
        
    </span>
    
    

    

</div>


        

        <div align="justify" class="article-style" itemprop="articleBody">
            <p>Multi-Agent Reinforcement Learning (MARL) has recently attracted much attention from the communities of machine learning, artificial intelligence, and multi-agent systems. As an interdisciplinary research field, there are so many unsolved problems, from cooperation to competition, from agent communication to agent modeling, from centralized learning to decentralized learning. MARL has been the main research focus of our lab. We are investigating the field from many perspectives. In the following, we introduce some of our studies. For detail, please refer to the papers.</p>

        </div>


        <div align="justify" class="article-style" itemprop="articleBody">
            
                
            
                
            
                
            
                
            
                
            
                
            
                
                    
                        <br>
                        

<h2 id="cooperation">Cooperation</h2>

<p>Cooperation has been one of the major research topics in MARL. We investigate multi-agent cooperation from many aspects, including adaptive learning rates, reward sharing, roles, and fairness.</p>

<h3 id="fen">FEN</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/fen.png" width="250" class="article-style" itemprop="image">
Fairness is essential for human society, contributing to stability and productivity. Similarly, fairness is also the key for many multi-agent systems. Taking fairness into multi-agent learning could help multi-agent systems become both efficient and stable. However, learning efficiency and fairness simultaneously is a complex, multi-objective, joint-policy optimization. To tackle these difficulties, we propose FEN, a novel hierarchical reinforcement learning model. We first decompose fairness for each agent and propose fair-efficient reward that each agent learns its own policy to optimize. To avoid multi-objective conflict, we design a hierarchy consisting of a controller and several sub-policies, where the controller maximizes the fair-efficient reward by switching among the sub-policies that provides diverse behaviors to interact with the environment. FEN can be trained in a fully decentralized way, making it easy to be deployed in real-world applications. Empirically, we show that FEN easily learns both fairness and efficiency and significantly outperforms baselines in a variety of multi-agent scenarios.</p>

<h3 id="adama">AdaMa</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/adama.png" width="450" class="article-style" itemprop="image">
In multi-agent reinforcement learning (MARL), the learning rates of actors and critic are mostly hand-tuned and fixed. This not only requires heavy tuning but more importantly limits the learning. With adaptive learning rates according to gradient patterns, some optimizers have been proposed for general optimizations, which however do not take into consideration the characteristics of MARL. We propose AdaMa to bring adaptive learning rates to cooperative MARL. AdaMa evaluates the contribution of actors’ updates to the improvement of Q-value and adaptively updates the learning rates of actors to the direction of maximally improving the Q-value. AdaMa could also dynamically balance the learning rates between the critic and actors according to their varying effects on the learning. Moreover, AdaMa can incorporate the second-order approximation to capture the contribution of pairwise actors’ updates and thus more accurately updates the learning rates of actors. Empirically, we show that AdaMa could accelerate the learning and improve the performance in a variety of multi-agent scenarios. Specifically, AdaMa not only obtains better performance than grid search on the learning rates, but also significantly reduces the training cost. The visualizations of learning rates during training clearly explain how and why AdaMa works.</p>

                                <div>
                                <h3>Publications</h3>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/fen/" itemprop="url">[NIPS&#39;19] Learning Fairness in Multi-Agent Systems</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Third Annual Conference on Neural Information Processing Systems</em> (NIPS), December 8-14, 2019.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 21%=<sup>1428</sup>&frasl;<sub>6743</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/fop/" itemprop="url">[ICML&#39;21] FOP: Factorizing Optimal Joint Policy of Maximum-Entropy Multi-Agent Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Tianhao Zhang, Yueheng Li, Chen Wang, Guangming Xie and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Eighth International Conference on Machine Learning (ICML), July 18-24, 2021
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 21%=<sup>1184</sup>&frasl;<sub>5513</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/eoi/" itemprop="url">[ICML&#39;21] The Emergence of Individuality</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Eighth International Conference on Machine Learning (ICML), July 18-24, 2021
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 3%=<sup>166</sup>&frasl;<sub>5513</sub>, <em>oral presentation</em>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/dae/" itemprop="url">[ICML&#39;22] Difference Advantage Estimation for Multi-Agent Policy Gradients</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Yueheng Li, Guangming Xie, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Ninth International Conference on Machine Learning (ICML), July 17-23, 2022
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 22%=<sup>1235</sup>&frasl;<sub>5630</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/dmac/" itemprop="url">[ICML&#39;22] Divergence-Regularized Multi-Agent Actor-Critic</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Kefan Su and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Ninth International Conference on Machine Learning (ICML)</em>, July 17-23, 2022
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 22%=<sup>1235</sup>&frasl;<sub>5630</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mbom/" itemprop="url">[NIPS&#39;22] Model-Based Opponent Modeling</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Xiaopeng Yu, Jiechuan Jiang, Wanpeng Zhang, Haobin Jiang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25.6%=<sup>2665</sup>&frasl;<sub>10411</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/i2q/" itemprop="url">[NIPS&#39;22] I2Q: A Fully Decentralized Q-Learning Algorithm</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25.6%=<sup>2665</sup>&frasl;<sub>10411</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/otc/" itemprop="url">[AAAI&#39;23] Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Seventh AAAI Conference on Artificial Intelligence</em> (AAAI), February 7-14, 2023.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 19%=<sup>1721</sup>&frasl;<sub>8777</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/adama/" itemprop="url">[AAMAS&#39;23] Adaptive Learning Rates for Multi-Agent Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Twenty-Second International Conference on Autonomous Agents and Multiagent Systems (AAMAS), May 29 - June 2, 2023.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 23%=<sup>237</sup>&frasl;<sub>1015</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/macpf/" itemprop="url">[ICLR&#39;23] More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiangxing Wang, Deheng Ye, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Eleventh International Conference on Learning Representations (ICLR)</em>, May 1-5, 2023.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/bql/" itemprop="url">Best Possible Q-Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    arXiv:2302.01188
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mdpo/" itemprop="url">Model-Based Decentralized Policy Optimization</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Hao Luo, Jiechuan Jiang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    arXiv:2302.08139
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mabcq/" itemprop="url">[ECAI&#39;23] Offline Decentralized Multi-Agent Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    26th European Conference on Artificial Intelligence (ECAI), Sept. 30-Oct. 4, 2023.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 24%=<sup>391</sup>&frasl;<sub>1631</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mipi/" itemprop="url">[NeurIPS&#39;23] Mutual-Information Regularized Multi-Agent Policy Iteration</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiangxing Wang, Deheng Ye, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Seventh Conference on Neural Information Processing Systems (NeurIPS), Dec. 10-16, 2023.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 26.1%=<sup>3221</sup>&frasl;<sub>12343</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mace/" itemprop="url">[AAAI&#39;24] Settling Decentralized Multi-Agent Coordinated Exploration by Novelty Sharing</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Haobin Jiang, Ziluo Ding, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), February 20-27, 2024
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 23.75%=<sup>2342</sup>&frasl;<sub>9862</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/ma2ql/" itemprop="url">[AAMAS&#39;24] Multi-Agent Alternate Q-Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Kefan Su, Siyuan Zhou, Jiechuan Jiang, Chuang Gan, Xiangjun Wang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Twenty-Third International Conference on Autonomous Agents and Multiagent Systems (AAMAS), May 6-10.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25%=<sup>229</sup>&frasl;<sub>883</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/dpo/" itemprop="url">[TMLR] A Fully Decentralized Surrogate for Multi-Agent Policy Optimization</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Kefan Su and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Transactions on Machine Learning Research (TMLR), 2024
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                </div>
                    
                
            
                
                    
                        <br>
                        

<h2 id="agent-communication">Agent Communication</h2>

<p>Biologically, communication is closely related to and probably originated from cooperation. For example, vervet monkeys can make different vocalizations to warn other members of the group about different predators. Similarly, communication can be crucially important in MARL for cooperation, especially for the scenarios where a large number of agents work in a collaborative way, such as autonomous vehicles planning, smart grid control, and multi-robot control. Communication enables agents to behave collaboratively.</p>

<h3 id="atoc">ATOC</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/atoc.png" width="220" class="article-style" itemprop="image">
There are several approaches for learning communication in MARL. However, information sharing among all agents or in predefined communication architectures that existing methods adopt can be problematic. When there is a large number of agents, agents hardly differentiate valuable information that helps cooperative decision making from globally shared information, and hence communication barely helps and could even jeopardize the learning of cooperation. Moreover, in real-world applications, it is costly that all agents communicate with each other, since receiving a large amount of information requires high bandwidth and incurs long delay and high computational complexity. Predefined communication architectures might help, however they restrict communication among specific agents and thus restrain potential cooperation. To tackle these difficulties, we propose an attentional communication model, ATOC, to enable agents to learn effective and efficient communication under partially observable distributed environment for large-scale MARL. Inspired by recurrent models of visual attention, we design an attention unit that receives encoded local observation and action intention of an agent and determines whether the agent should communicate with other agents to cooperate in its observable field. If so, the agent, called <em>initiator</em>, selects collaborators to form a communication group for coordinated strategies. The communication group dynamically changes and retains only when necessary. We exploit a bi-directional LSTM unit as the communication channel to connect each agent within a communication group. The LSTM unit takes as input internal states and returns thoughts that guide agents for coordinated strategies. The LSTM unit selectively outputs important information for cooperative decision making, which makes it possible for agents to learn coordinated strategies in dynamic communication environments. ATOC agents are able to develop coordinated and sophisticated strategies in various cooperation scenarios.</p>

<h3 id="i2c">I2C</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/i2c.png" width="300" class="article-style" itemprop="image">
Most existing work of multi-agent communication focuses on broadcast communication, which is not only impractical but also leads to information redundancy that could even impair the learning process. To tackle these difficulties, we propose Individually Inferred Communication (I2C), a simple yet effective model to enable agents to learn a prior for agent-agent communication. The prior knowledge is learned via causal inference and realized by a feed-forward neural network that maps the agent’s local observation to a belief about who to communicate with. The influence of one agent on another is inferred via the joint action-value function in multi-agent reinforcement learning and quantified to label the necessity of agent-agent communication. Furthermore, the agent policy is regularized to better exploit communicated messages. Empirically, we show that I2C can not only reduce communication overhead but also improve the performance in a variety of multi-agent cooperative scenarios, comparing to existing methods.</p>

                                <div>
                                <h3>Publications</h3>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/atoc/" itemprop="url">[NIPS&#39;18] Learning Attentional Communication for Multi-Agent Cooperation</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Second Annual Conference on Neural Information Processing Systems</em> (NIPS), December 3-8, 2018.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 21%=<sup>1011</sup>&frasl;<sub>4856</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/dgn/" itemprop="url">[ICLR&#39;20] Graph Convolutional Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang, Chen Dun, Tiejun Huang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>International Conference on Learning Representation</em> (ICLR), April 26-30, 2020.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 26.5%=<sup>687</sup>&frasl;<sub>2594</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/i2c/" itemprop="url">[NIPS&#39;20] Learning Individually Inferred Communication for Multi-Agent Cooperation</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Ziluo Ding, Tiejun Huang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Fourth Annual Conference on Neural Information Processing Systems</em> (NIPS), December 6-12, 2020.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 1%=<sup>105</sup>&frasl;<sub>9454</sub>, <em>oral</em>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/ltos/" itemprop="url">[NIPS&#39;22] Learning to Share in Multi-Agent Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Yuxuan Yi, Ge Li, Yaowei Wang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25.6%=<sup>2665</sup>&frasl;<sub>10411</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/seqcomm/" itemprop="url">Multi-Agent Sequential Decision-Making via Communication</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Ziluo Ding, Kefan Su, Weixin Hong, Liwen Zhu, Tiejun Huang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    arXiv:2209.12713
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/endi/" itemprop="url">[ICML&#39;23] Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Ziluo Ding, Wanpeng Zhang, Junpeng Yue, Xiangjun Wang, Tiejun Huang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Fortieth International Conference on Machine Learning (ICML), July 23-29, 2023.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 27.9%=<sup>1827</sup>&frasl;<sub>6538</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/acl23/" itemprop="url">[ACL&#39;23] Multi-Agent Language Learning: Symbolic Mapping</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Yicheng Feng and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    61st Annual Meeting of the Association for Computational Linguistics (ACL), <em>Findings</em>, July 9-14, 2023.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/position/" itemprop="url">[AAAI&#39;24] Learning Multi-Object Positional Relationships via Emergent Communication</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Yicheng Feng, Boshi An, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), February 20-27, 2024
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 23.75%=<sup>2342</sup>&frasl;<sub>9862</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                </div>
                    
                
            
                
                    
                        <br>
                        

<h2 id="reinforcement-learning">Reinforcement Learning</h2>

<p>Besides MARL, we also pay attention to the fundamentals of reinforcement learning including the tradeoff between exploration and exploitation, and experience replay for off-policy RL.</p>

<h3 id="gene">GENE</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/gene.png" width="330" class="article-style" itemprop="image">
Sparse reward is one of the biggest challenges in RL. We propose a novel method called Generative Exploration and Exploitation (GENE) to overcome sparse reward. GENE dynamically changes the start state of agent to the generated novel state to encourage the agent to explore the environment or to the generated rewarding state to boost the agent to exploit the received reward signal. GENE relies on no prior knowledge about the environment and can be combined with any RL algorithm, no matter on-policy or off-policy, single-agent or multi-agent. Empirically, we demonstrate that GENE significantly outperforms existing methods in four challenging tasks with only binary rewards indicating whether or not the task is completed, including Maze, Goal Ant, Pushing, and Cooperative Navigation. The ablation studies verify that GENE can adaptively tradeoff between exploration and exploitation as the learning progresses by automatically adjusting the proportion between generated novel states and rewarding states, which is the key for GENE to solving these challenging tasks effectively and efficiently.</p>

<h3 id="ver">VER</h3>

<p><img style="float: right;  margin: 10px 0px 0px 20px;" src = "/img/project/ver.png" width="500" class="article-style" itemprop="image">
Experience replay enables off-policy RL agents to utilize past experiences to maximize the cumulative reward. Prioritized experience replay that weighs experiences by the magnitude of their temporal-difference error (|TD|) significantly improves the learning efficiency. But how |TD| is related to the importance of experience is not well understood. We address this problem from an economic perspective, by linking |TD| to value of experience, which is defined as the value added to the cumulative reward by accessing the experience. We theoretically show the value metrics of experience are upper-bounded by |TD| for Q-learning. Furthermore, we successfully extend our theoretical framework to maximum-entropy RL by deriving the lower and upper bounds of these value metrics for soft Q-learning, which turn out to be the product of |TD| and “on-policyness” of the experiences. Our framework links two important quantities in RL: |TD| and value of experience. We empirically show that the bounds hold in practice, and experience replay using the upper bound as priority improves maximum-entropy RL in Atari games.</p>

                                <div>
                                <h3>Publications</h3>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/gene/" itemprop="url">[AAAI&#39;20] Generative Exploration and Exploitation</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiechuan Jiang and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Fourth AAAI Conference on Artificial Intelligence</em> (AAAI), February 7-12, 2020.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 21%=<sup>1591</sup>&frasl;<sub>7737</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/ver/" itemprop="url">Revisiting Prioritized Experience Replay: A Value Perspective</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Ang Li, Zongqing Lu, and Chenglin Miao
                
            </div>

            <div class="pub-publication">
                
                    arXiv:2102.03261
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/corro/" itemprop="url">[ICML&#39;22] Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Haoqi Yuan and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Thirty-Ninth International Conference on Machine Learning (ICML), July 17-23, 2022
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 22%=<sup>1235</sup>&frasl;<sub>5630</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/cabi/" itemprop="url">[NIPS&#39;22] Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Xiu Li, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25.6%=<sup>2665</sup>&frasl;<sub>10411</sub>, <em>spotlight</em>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mcq/" itemprop="url">[NIPS&#39;22] Mildly Conservative Q-Learning for Offline Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Xiaoteng Ma, Xiu Li, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Thirty-Sixth Annual Conference on Neural Information Processing Systems</em> (NIPS), November 28 - December 9, 2022.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 25.6%=<sup>2665</sup>&frasl;<sub>10411</sub>, <em>spotlight</em>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/saw/" itemprop="url">[ICLR&#39;23] State Advantage Weighting for Offline RL</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Aicheng Gong, Le Wan, Zongqing Lu, and Xiu Li
                
            </div>

            <div class="pub-publication">
                
                    Eleventh International Conference on Learning Representations (ICLR), <em>Tiny Papers</em>, May 1-5, 2023.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/smr/" itemprop="url">Off-Policy RL Algorithms Can be Sample-Efficient for Continuous Control via Sample Multiple Reuse</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Le Wan, Zongqing Lu, and Xiu Li
                
            </div>

            <div class="pub-publication">
                
                    arXiv:2305.18443
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/transformer/" itemprop="url">[TMLR] A Survey on Transformers in Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Wenzhe Li, Hao Luo, Zichuan Lin, Chongjie Zhang, Zongqing Lu, and Deheng Ye
                
            </div>

            <div class="pub-publication">
                
                    Transactions on Machine Learning Research (TMLR), 2023.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/gap/" itemprop="url">[AAMAS&#39;24] Towards Understanding How to Reduce Generalization Gap in Visual Reinforcement Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Le Wan, Xiu Li, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Twenty-Third International Conference on Autonomous Agents and Multiagent Systems (AAMAS), <em>extended abstract</em>, May 6-10.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/seabo/" itemprop="url">[ICLR&#39;24] SEABO: A Simple Search-Based Method for Offline Imitation Learning</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Xiaoteng Ma, Le Wan, Runze Liu, Xiu Li, Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    <em>Eighth International Conference on Learning Representations (ICLR)</em>, May 7-11, 2024.
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 31%)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/par/" itemprop="url">[ICML&#39;24] Cross-Domain Policy Adaptation by Capturing Representation Mismatch</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiafei Lyu, Chenjia Bai, Jing-Wen Yang, Zongqing Lu, and Xiu Li
                
            </div>

            <div class="pub-publication">
                
                    Forty-first International Conference on Machine Learning (ICML), July 21-27, 2024
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 27.5%=<sup>2609</sup>&frasl;<sub>9473</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/corep/" itemprop="url">[ICML&#39;24] Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin Representation</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Wanpeng Zhang, Yilin Li, Boyu Yang, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Forty-first International Conference on Machine Learning (ICML), July 21-27, 2024
                
            </div>
            <div class="pub-publication">
                
                    (Acceptance Rate: 27.5%=<sup>2609</sup>&frasl;<sub>9473</sub>)
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                
                                
                                
                                
                                <dl> <div itemscope itemtype="http://schema.org/CreativeWork">
    <div class="row">
        <div class="col-md-12">

            <span itemprop="name">
                <a href="https://z0ngqing.github.io/publication/mipo/" itemprop="url">[ACL&#39;24] Language Model Adaption for Reinforcement Learning with Natural Language Action Space</a>
            </span>

            <div class="pub-authors" itemprop="author">
                
                Jiangxing Wang, Jiachen Li, Xiao Han, Deheng Ye, and Zongqing Lu
                
            </div>

            <div class="pub-publication">
                
                    Annual Meeting of the Association for Computational Linguistics, August 11-16, 2024.
                
            </div>
            <div class="pub-publication">
                
            </div>


        </div>
    </div>
</div>
 </dl>
                                
                                
                                
                                </div>
                    
                
            
                
            
                
            
        </div>

        <div>
        
        </div>
    </article>
    
    <nav>
    <ul class="pager">
    	
        
        <li class="previous"><a href="https://z0ngqing.github.io/project/rlapp/"><span aria-hidden="true">&larr;</span> RL/MARL Applications</a></li>
        
        

        
        
        
    </ul>
</nav>


</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">

            &copy; 2024 Zongqing Lu &middot; 

            Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://z0ngqing.github.io/js/jquery-1.12.3.min.js"></script>
        <script src="https://z0ngqing.github.io/js/bootstrap.min.js"></script>
        <script src="https://z0ngqing.github.io/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-88925956-1', 'auto');
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

